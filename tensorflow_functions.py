# -*- coding: utf-8 -*-
"""TensorFlow_Functions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q-HHw_B1zoRA9-qvUYnT96dFXQJE01Mh

### Helper functions for future projects
"""

import tensorflow as tf

# import & resize image for model use

def peebs_load_and_prepare_image(filename, img_shape=224, scale = True):
  """
  Reads an image from filename and turns it into tensor of size (224, 224, 3)

  Parameters
  ----------
  filename (str)
  img_shape (int)
  scale (bool): whether to scale the pixel values to range (0, 1)
  """
  
  # Read the image
  img = tf.io.read_file(filename)
  # Decode into tensor
  img = tf.image.decode_jpeg(img)
  # Resize the image
  img = tf.image.resize(img, [img_shape, img_shape])
  if scale:
    # Rescale the image (get all values from 0 and 1)
    return img/255.
  else:
    return img

# Remix scikit-learn confusion matrix
import itertools
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix


def peebs_confusion_matrix(y_true, y_pred, classes = None, figsize = (10, 10), text_size = 15, norm = False, savefig = False):
  """
  Compare predictions and ground truth labels 

  classes should be passed in order to have a labelled confusion matrix | integer values will be used otherwise

  Args:
  y_true: Array of truth labels (must be shaped as y_pred)
  y_pred: Array of predicted labels (must be same shape as y_true)
  classes: Arrays of class labels (e.g. string form). If `None`, integer labels are used
  figsize: Size of output figure (default(10, 10))
  text_size: Size of the output figure text (default = 15)
  norm: Normalize values or not (default = False)
  savefig: save confusion matrix to file (default = False)
  

  returns:
    A labelled confusion matrix plot comparing y_true and y_pred
  """

  # Create the confusion matrix
  cm = confusion_matrix(y_true, y_pred)
  cm_norm = cm.astype("float") / cm.sum(axis = 1)[:, np.newaxis] #normalize it
  n_classes = cm.shape[0] 

  # Plot the figure 
  fig, ax = plt.subplots(figsize = figsize)
  cax = ax.matshow(cm, cmap = plt.cm.Blues)# colors will represent how 'correct' a class is, darker == better
  fig.colorbar(cax)

  # List of classe?
  if classes:
    labels = classes
  else:
    labels = np.arange(cm.shape[0])

  # Label the axes
  ax.set(title="Confusion Matrix",
         xlabel = "Predicted Label",
         y_label =  "True Label",
         xticks = np.arange(n_classes),
         yticks = np.arange(n_classes),
         xtickslabels = labels,
         ytickslabels = labels)
  
  # Make x-axis labels appear on bottom 
  ax.xaxis.set_label_position("bottom")
  ax.xaxis.tick_bottom()

  # Set the threshold for different colors
  threshold  = (cm.max() + cm.min()) / 2.

  # Plot the text on each cell
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    if norm:
      plt.text(j, i, f"{cm[i, j]} {cm_norm[i, j]*100:.1f}%)",
               horizontalalignment = "center",
               color = "white" if cm[i, j] > threshold else "black",
               size = text_size)
    else:
      plt.text(j, i, f"{cm[i, j]}",
               horizontalalignment = "center",
               color = "white" if cm[i, j] > threshold else "black",
               size = text_size)
      
  # Save the figure to the current working directory
  if savefig:
    fig.savefig("confusion_matrix.png")

# Make a funciton to predict on images and plot them (works with multi-class)
def peebs_pred_and_plot(model, filename, class_names):
  """
  imports an image and makes a prediction using the trained model and plots
  the image with the predicted class as title
  """

  # Import the target image and process it
  img = peebs_load_and_prepare_image(filename)

  # Make a prediction
  pred = model.predict(df.expand_dims(img, axis = 0))

  # Get the predicted class
  if len(pred[0]) > 1: #check for multiclass
     pred_class = class_names[pred.argmax()] # if more than one output, it takes the max
  else:
    pred_class = class_names[int(tf.round(pred)[0][0])] #if only one output, round

  # Plot the image and predicted class
  plt.imshow(img)
  plt.title(f"Prediction: {pred_class}")
  plt.axis(False);

import datetime

def peebs_tensorboard_callbacks(dir_name, experiment_name):
  """
  Creates a tensorboard callback instance to store log files

  Stores log files with the filepath:
    "dir_name/experiment_name/current_datetime/"

  Args:
    dir_name: target directory to store TensorBoard log files
    experiment_name: name of experiment directory (e.g. efficientnet_model_1)
  """

  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir=log_dir
  )
  print(f"Saving TensorBoard log files to: {log_dir}")
  return tensorboard_callback

# Plot the validation and training data separately
import matplotlib.pyplot as plt

def peebs_plot_loss_curves(history):
  """
  returns separate loss curves for training and validation metrics

  Args:
    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)
  """

  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  # Plot loss
  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  # Plot accuracy
  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();

def peebs_compare_historys(original_history, new_history, initial_epochs=5):
    """
    Compares two TensorFlow model History objects.
    
    Args:
      original_history: History object from original model (before new_history)
      new_history: History object from continued model training (after original_history)
      initial_epochs: Number of epochs in original_history (new_history plot starts from here) 
    """
    
    # Get original history measurements
    acc = original_history.history["accuracy"]
    loss = original_history.history["loss"]

    val_acc = original_history.history["val_accuracy"]
    val_loss = original_history.history["val_loss"]

    # Combine original history with new history
    total_acc = acc + new_history.history["accuracy"]
    total_loss = loss + new_history.history["loss"]

    total_val_acc = val_acc + new_history.history["val_accuracy"]
    total_val_loss = val_loss + new_history.history["val_loss"]

    # Make plots
    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(total_acc, label='Training Accuracy')
    plt.plot(total_val_acc, label='Validation Accuracy')
    plt.plot([initial_epochs-1, initial_epochs-1],
              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(2, 1, 2)
    plt.plot(total_loss, label='Training Loss')
    plt.plot(total_val_loss, label='Validation Loss')
    plt.plot([initial_epochs-1, initial_epochs-1],
              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()

# Function for zipfile
import zipfile

def peebs_unzip_data(filename):
  """
  Unzips filename into the current working directory.
  Args:
    filename (str): a filepath to a target zip folder to be unzipped.
  """
  zip_ref = zipfile.ZipFile(filename, "r")
  zip_ref.extractall()
  zip_ref.close()

# Walk through an image classificaiton directeory

import os

def walk_through_dir(dir_path):
  """
  Walks through dir_path returning its contents.
  Args:
    dir_path (str): target directory
  
  Returns:
    A print out of:
      number of subdiretories in dir_path
      number of images (files) in each subdirectory
      name of each subdirectory
  """
  for dirpath, dirnames, filenames in os.walk(dir_path):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

# Function to evaluate: accuracy, precision, recall, f1-score
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def peebs_calculate_results(y_true, y_pred):
  """
  Calculates model accuracy, precision, recall and f1 score of a binary classification model.
  Args:
      y_true: true labels in the form of a 1D array
      y_pred: predicted labels in the form of a 1D array
  Returns a dictionary of accuracy, precision, recall, f1-score.
  """
  # Calculate model accuracy
  model_accuracy = accuracy_score(y_true, y_pred) * 100
  # Calculate model precision, recall and f1 score using "weighted average
  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average="weighted")
  model_results = {"accuracy": model_accuracy,
                  "precision": model_precision,
                  "recall": model_recall,
                  "f1": model_f1}
  return model.results

